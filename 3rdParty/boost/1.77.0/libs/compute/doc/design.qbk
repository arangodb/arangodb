[/===========================================================================
 Copyright (c) 2013-2015 Kyle Lutz <kyle.r.lutz@gmail.com>

 Distributed under the Boost Software License, Version 1.0
 See accompanying file LICENSE_1_0.txt or copy at
 http://www.boost.org/LICENSE_1_0.txt
=============================================================================/]

[section:design Design]

[section Library Architecture]

The Boost Compute library consists of several different components. The core
layer provides a "thin" C++ wrapper over the OpenCL API. This includes classes
to manage OpenCL objects such as
[classref boost::compute::device device]'s,
[classref boost::compute::device kernel]'s and
[classref boost::compute::device command_queue]'s.

On top of the core layer is a partial implementation of the C++ standard
library providing common containers (e.g.
[classref boost::compute::vector vector<T>],
[classref boost::compute::array array<T, N>]) along with common algorithms
(e.g. [funcref boost::compute::transform transform()] and
[funcref boost::compute::sort sort()]).

The library also provides a number of "fancy" iterators (e.g.
[classref boost::compute::transform_iterator transform_iterator] and
[classref boost::compute::permutation_iterator permutation_iterator]) which
enhance the functionality of the standard algorithms.

Boost.Compute also supplies a number of facilities for interoperation with
other C and C++ libraries. See the section on [link boost_compute.interop
interoperability] for more information.

See the [link boost_compute.reference.api_overview API Overview] section for
a full list of functions, classes, and macros provided by Boost.Compute.

[endsect] [/ library architecture]

[section Why OpenCL]

Boost.Compute uses [@http://en.wikipedia.org/wiki/OpenCL OpenCL] as its
interface for executing code on parallel devices such as GPUs and multi-core
CPUs.

OpenCL was chosen for a number of reasons:

* Vendor-neutral, standard C/C++, and doesn't require a special compiler,
non-standard pragmas, or compiler extensions.
* It is not just another parallel-library abstraction layer, it provides direct
access to the underlying hardware.
* Its runtime compilation model allows for kernels to be optimized and tuned
dynamically for the device present when the application is run rather that the
device that was present when the code was compiled (which is often a separate
machine).
* Using OpenCL allows Boost.Compute to directly interoperate with other OpenCL
libraries (such as VexCL and OpenCV), as well as existing code written with
OpenCL.
* The "thin" C++ wrapper provided by Boost.Compute allows the user to break-out
and write their own custom kernels when the provided APIs are not suitable.

[endsect] [/ why opencl]

[endsect]
