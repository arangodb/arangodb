version: 2.1

orbs:
  aws-cli: circleci/aws-cli@4.1.1
  aws-ecr: circleci/aws-ecr@9.0.1
  
parameters:
  enterprise-commit:
    type: string
    default: ""
  build-docker-image:
    type: string
    default: "arangodb/ubuntubuildarangodb-devel:6"
  test-docker-image:
    type: string
    default: public.ecr.aws/b0b8h2r4/test-ubuntu:23.10-5b6113b7
  # Unused here, but it will be forwarded from config and will cause errors if not defined
  enterprise-branch:
    type: string
    default: ""
  dont-cancel-pipelines:
    type: boolean
    default: false
  create-docker-images:
    type: boolean
    default: false
  nightly:
    type: boolean
    default: false
  replication-two:
    type: boolean
    default: false
  sanitizer:
    type: string
    default: ""
  ui:
    type: string
    default: "off"
  ui-deployment:
    type: string
    default: ""
  ui-testsuites:
    type: string
    default: ""
  c-compiler:
    type: string
    default: "clang"
  cxx-compiler:
    type: string
    default: "clang++"
  # these are basically global constants
  build-targets:
    type: string
    default: "arangodb"
    # The arangodb target consists of arangod and the list of client-tools which already
    # conditionally contains arangobackup and arangosh, depending on whether we build in
    # enterprise mode, and whether we build with V8 or not.
    # This should also improve build times because this way the individual targets can be
    # built in parallel (a list of individual targets is built serially).
  test-build-targets:
    type: string
    default: "arangodbtests fuertetest"

commands:
  checkout-arangodb:
    parameters:
      destination:
        type: string
      with-submodules:
        type: boolean
    steps:
      - run:
          name: Checkout ArangoDB
          command: |
            mkdir -p << parameters.destination >>
            cd << parameters.destination >>
            echo << pipeline.git.revision >>
            git init
            git remote add origin https://github.com/arangodb/arangodb.git
            echo "Fetching stuff"
            git fetch --depth 1 origin << pipeline.git.revision >>
            git checkout << pipeline.git.revision >>
      - when:
          condition: << parameters.with-submodules >>
          steps:
            - run:
                name: "Checkout submodules"
                command: |
                  cd << parameters.destination >>
                  git submodule init
                  git submodule update --recursive --depth 1 --jobs 8

  checkout-enterprise:
    description: "Checkout enterprise code"
    parameters:
      destination:
        type: string
    steps:
      - add_ssh_keys:
          fingerprints:
            - "f9:49:75:1a:ad:44:89:10:4b:3c:70:70:ba:d3:c3:ce"
      - run:
          name: Checkout Enterprise
          environment:
            GIT_SSH_COMMAND: "ssh -o StrictHostKeyChecking=no"
          command: |
            mkdir -p << parameters.destination >>
            cd << parameters.destination >>
            git clone git@github.com:arangodb/enterprise.git .
            git reset --hard << pipeline.parameters.enterprise-commit >>

jobs:
  minimal-checkout:
    docker:
      - image: cimg/base:current
    resource_class: small
    environment:
      GIT_SSH_COMMAND: ssh -v
    steps:
      - checkout-arangodb:
          with-submodules: false
          destination: "/home/circleci/project"
      - checkout-enterprise:
          destination: "/home/circleci/project/enterprise"
      - run:
          name: Checkout rta-makedata
          command: |
            # we are only interested in the rta-makedata submodule because we want to run eslint on it,
            # but we do not care about the other submodules (specifically we do _not_ want to clone v8)
            git submodule update --init 3rdParty/rta-makedata
      - persist_to_workspace:
          root: .
          paths:
            - .

  check-log-ids:
    docker:
      - image: cimg/python:3.11.1
    resource_class: small
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Install pyyaml
          command: |
            python -m pip install --upgrade pip
            pip install pyyaml
      - run:
          name: Check LogIDs
          command: |
            python3 utils/checkLogIds.py

  check-metrics-docs:
    docker:
      - image: cimg/python:3.11.1
    resource_class: small
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Install pyyaml
          command: |
            python -m pip install --upgrade pip
            pip install pyyaml
      - run:
          name: Check LogIDs
          command: |
            python3 utils/generateAllMetricsDocumentation.py

  clang-format:
    docker:
      - image: alpine:3.15
    resource_class: small
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Install clang-format
          command: |
            apk add --no-cache git bash coreutils grep clang-extra-tools=12.0.1-r1
      - run:
          name: Print clang-format version
          command: clang-format --version
      - run:
          name: Run clang-format
          command: |
            scripts/clang-format-circleci.sh
      - run:
          name: Store diff
          command: |
            OUTCOME_BASE="/tmp/clang_format_outcome"
            OUTCOME_COMMUNITY=$OUTCOME_BASE/community.diff
            OUTCOME_ENTERPRISE=$OUTCOME_BASE/enterprise.diff
            mkdir -p $OUTCOME_BASE
            if [ -n "$(git status --porcelain)" ] ; then
                git diff | tee $OUTCOME_COMMUNITY
            fi
            if [ -n "$(git -C enterprise status --porcelain)" ] ; then
                git -C enterprise diff | tee $OUTCOME_ENTERPRISE
            fi
            if [ -f "$OUTCOME_COMMUNITY" ] || [ -f "$OUTCOME_ENTERPRISE" ]; then
              exit 1
            fi
      - store_artifacts:
          path: /tmp/clang_format_outcome

  eslint:
    docker:
      - image: alpine:3.17
    resource_class: small
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Install eslint
          command: |
            apk add --no-cache npm curl jq
            npm -g install eslint@8.46.0
      - run:
          name: Run eslint
          command: |
            utils/eslint.sh
      - run:
          name: "Cancel other workflows"
          when: on_fail
          command: |
            ## Get the IDs of currently running/on_hold workflows, but exclude ourselves
            curl --header "Circle-Token: $CIRCLECI_TOKEN" --request GET "https://circleci.com/api/v2/pipeline/${CIRCLE_PIPELINE_ID}/workflow" | \
                jq -r '.items[]|select(.id != "'${CIRCLE_WORKFLOW_ID}'" and (.status == "on_hold" or .status == "running")) | .id' >> WF_to_cancel.txt

            ## Cancel any currently running/on_hold workflow with the same name
            if [ -s WF_to_cancel.txt ]; then
              echo "Cancelling the following workflow(s):"
              cat WF_to_cancel.txt 
              while read WF_ID;
                do
                  curl --header "Circle-Token: $CIRCLECI_TOKEN" --request POST https://circleci.com/api/v2/workflow/$WF_ID/cancel
                done < WF_to_cancel.txt
            else
              echo "Nothing to cancel"
            fi

  build-frontend:
    docker:
      - image: << pipeline.parameters.build-docker-image >>
    resource_class: large
    steps:
      - checkout-arangodb:
          with-submodules: false
          destination: "/root/project"
      - run:
          name: Build frontend
          command: |
            cd js/apps/system/_admin/aardvark/APP/react
            yarn install
            yarn build
      - persist_to_workspace:
          root: .
          paths:
            - js/apps/system/_admin/aardvark/APP/react/build

  compile-linux:
    parameters:
      preset:
        type: string
      enterprise:
        type: boolean
      build-tests:
        type: boolean
        default: true
      build-v8:
        type: boolean
        default: true
      publish-artifacts:
        type: boolean
        default: true
      resource-class:
        type: string
      s3-prefix:
        type: string
        default: ""
      arch:
          type: string
    docker:
      - image: << pipeline.parameters.build-docker-image >>
    resource_class: << parameters.resource-class >>
    environment:
      GIT_SSH_COMMAND: ssh
      SCCACHE_ERROR_LOG: /tmp/sccache.log
      SCCACHE_LOG: info,sccache::cache=debug,sccache::compiler::compiler=debug
      SCCACHE_S3_KEY_PREFIX: << parameters.s3-prefix >>
      CC: /tools/clang
      CXX: /tools/clang++
    steps:
      - checkout-arangodb:
          with-submodules: true
          destination: "/root/project"
      - when:
          condition: << parameters.enterprise >>
          steps:
            - checkout-enterprise:
                destination: "/root/project/enterprise"
      - run:
          name: Print SCCache Settings
          command: sccache -s
      - run:
          name: Configure
          command: |
            cmake --preset << parameters.preset >> \
              -DCMAKE_C_COMPILER=<< pipeline.parameters.c-compiler >> \
              -DCMAKE_CXX_COMPILER=<< pipeline.parameters.cxx-compiler >> \
              -DCMAKE_EXE_LINKER_FLAGS="-fuse-ld=lld" \
              -DCMAKE_LIBRARY_PATH=$OPENSSL_ROOT_DIR/lib \
              -DCMAKE_C_COMPILER_LAUNCHER=sccache \
              -DCMAKE_CXX_COMPILER_LAUNCHER=sccache \
              -DOPENSSL_ROOT_DIR=/opt \
              -DCMAKE_INSTALL_PREFIX=/
      - run:
          name: Build
          command: |
            TARGETS="<< pipeline.parameters.build-targets >>"
            if [ << parameters.build-tests >> = true ]; then
              TARGETS="$TARGETS << pipeline.parameters.test-build-targets >>"
            fi
            echo "Building targets: $TARGETS"
            cmake --build --preset << parameters.preset >> --parallel 16 --target $TARGETS
      - when:
          condition:
            or:
              -  not:
                  equal: [ << pipeline.parameters.ui >>, ""]
              - << pipeline.parameters.create-docker-images >>
          steps:
            - run:
                root: .
                name: get aux binaries
                command: |
                  set -x
                  STARTER_REV=$(grep -Po "STARTER_REV \"\Kv\d+\.\d+\.\d+[a-z0-9-]*" VERSIONS)
                  RCLONE_VERSION=$(grep -Po "RCLONE_VERSION \"\K\d+\.\d+\.\d+" VERSIONS)
                  arch="<<parameters.arch>>"
                  if test "$arch" == "x64"; then
                    arch="amd64"
                  fi
                  curl -s -L -o build/bin/arangodb "https://github.com/arangodb-helper/arangodb/releases/download/$STARTER_REV/arangodb-linux-$arch"
                  chmod a+x build/bin/arangodb
                  if [ << parameters.enterprise >> = true ]; then
                    curl -s -L -o build/bin/rclone-arangodb "https://github.com/arangodb/oskar/raw/master/rclone/v$RCLONE_VERSION/rclone-arangodb-linux-$arch"
                    chmod a+x build/bin/rclone-arangodb
                  fi
      - when:
          condition: << pipeline.parameters.create-docker-images >>
          steps:
            - run:
                name: Create install package
                command: |
                  mkdir install
                  # Note: ATM this will rebuild the frontend
                  DESTDIR=`pwd`/install cmake --build --preset << parameters.preset >> --parallel 16 --target install
                  cp build/bin/arangodb ./install/usr/bin/
                  if [ << parameters.enterprise >> = true ]; then
                    cp build/bin/rclone-arangodb ./install/usr/bin/
                  fi
                  strip ./install/usr/bin/arango*
                  strip ./install/usr/sbin/arangod
                  tar -czf install.tar.gz -C install ./
      - run:
          name: Size leaderboard
          command: |
            ls -Ssha build/bin/*.a
      - run:
          name: Cleanup build directory
          command: |
            find build/ -iname *.a -delete || true
            find build/ -iname *.o -delete || true
            find build/ -iname *.o.d -delete || true
            rm js/apps/system/_admin/aardvark/APP/react/node_modules -rf
      - run:
          name: List build artifacts
          command: |
            ls -Ssha build/bin/
      - run:
          name: SCCache Statistics
          command: sccache -s
      - store_artifacts:
          path: /tmp/sccache.log
      - when:
          condition: << parameters.publish-artifacts >>
          steps:
            - store_artifacts:
                path: build/bin/arango*
            - persist_to_workspace:
                root: .
                paths:
                  - VERSIONS
                  - ARANGO-VERSION
                  - build/compile_commands.json
                  - CMakePresets.json
                  - install.tar.gz
                  - build/bin
                  - build/etc
                  - build/3rdParty/iresearch/external/snowball/libstemmer/
                  - build/build_version.cc
                  - scripts/
                  - js/
                  - enterprise/js
                  - etc/
                  - tests/js
                  - enterprise/tests/js
                  - utils
                  - 3rdParty/iresearch/tests/resources
                  - 3rdParty/rta-makedata
                  - tsan_arangodb_suppressions.txt
                  - ubsan_arangodb_suppressions.txt
                  - lsan_arangodb_suppressions.txt

  create-docker-image:
    parameters:
      resource-class:
          type: string
      arch:
          type: string
      tag:
          type: string
    docker:
      - image: cimg/base:current
    resource_class: << parameters.resource-class >>
    steps:
      - aws-cli/setup:
          role_arn: "arn:aws:iam::242063586340:role/CircleCI-Container-Handler"
      - aws-ecr/ecr_login:
          public_registry: true
      - setup_remote_docker:
            docker_layer_caching: true
      - attach_workspace:
          at: .
      - run:
          name: Create Docker Image
          command: |
            cd scripts/docker/deploy
            mkdir install
            tar -xzf ../../../install.tar.gz -C install
            docker build --platform linux/<< parameters.arch >> --build-arg arch=<< parameters.arch >> -t << parameters.tag >> --file deploy-alpine.dockerfile .
            echo "Pushing image << parameters.tag >>"
            docker push << parameters.tag >>

  run-linux-tests:
    docker:
      - image: << pipeline.parameters.test-docker-image >>
    parameters:
      suiteName:
        type: string
      suites:
        type: string
      size:
        type: string
      extraArgs:
        type: string
        default: ""
      buckets:
        type: integer
        default: 1
      cluster:
        type: boolean
      timeLimit:
        type: integer
        default: 1800
    resource_class: << parameters.size >>
    parallelism: << parameters.buckets >>
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Enabled coredumps
          command: ulimit -c unlimited
      - run:
          name: Log processes
          command: |
            export PS_FORMAT="pid,%cpu,%mem,rss,thcount,oom,oomadj,args"
            ps | head -n 1
            echo "======"
            while true; do
              sleep 3
              ps -a | grep "[a]rangod " || true | while read line ; do echo "$(date +"%T") > $line" ; done ;
              echo "======"
            done
          background: true
      - when:
          condition:
            not:
              equal: [ << pipeline.parameters.sanitizer >>, ""]
          steps:
            - run:
                name: Symbolizer server
                command: ./utils/llvm-symbolizer-server.py
                background: true
      - run:
          name: Run << parameters.suiteName >> tests
          # we increase the no_output_timeout so our own timeout mechanism can kick in and gather more information
          no_output_timeout: 20m
          command: |
            mkdir work
            if [ "<< pipeline.parameters.sanitizer >>" = "alubsan" ]; then
              export ASAN_OPTIONS="log_exe_name=true:log_path=`pwd`/work/alubsan.log:handle_ioctl=true:check_initialization_order=true:detect_container_overflow=true:detect_stack_use_after_return=false:detect_odr_violation=1:strict_init_order=true:external_symbolizer_path=`pwd`/utils/llvm-symbolizer-client.py"
              export LSAN_OPTIONS="log_exe_name=true:log_path=`pwd`/work/alubsan.log:suppressions=lsan_arangodb_suppressions.txt:print_suppressions=0"
              export UBSAN_OPTIONS="log_exe_name=true:log_path=`pwd`/work/alubsan.log:print_stacktrace=1:suppressions=ubsan_arangodb_suppressions.txt:print_suppressions=0:external_symbolizer_path=`pwd`/utils/llvm-symbolizer-client.py"
              export SAN_MODE=alubsan
            elif [ "<< pipeline.parameters.sanitizer >>" = "tsan" ]; then
              export TSAN_OPTIONS="log_exe_name=true:log_path=`pwd`/work/tsan.log:detect_deadlocks=true:second_deadlock_stack=1:suppressions=tsan_arangodb_suppressions.txt:print_suppressions=0:external_symbolizer_path=`pwd`/utils/llvm-symbolizer-client.py"
              export SAN_MODE=tsan
            fi

            # check if promtool is available and if so set the environment variable to enable the according tests
            if command -v promtool &> /dev/null; then
              export PROMTOOL_PATH=`command -v promtool`
            fi

            export TIMELIMIT=<< parameters.timeLimit >>
            # Note: we need the leading space for extraArgs to avoid a parsing issue in argparse
            python3 -u scripts/test/test_launch_controller.py << parameters.suites >> \
              --testBuckets $CIRCLE_NODE_TOTAL/$CIRCLE_NODE_INDEX \
              --cluster << parameters.cluster >> \
              --extraArgs " << parameters.extraArgs >>"
      - run:
          name: Copy test results
          when: always
          command: |
            ls -la ./work/
            mkdir test-results
            find testrunXml -iname *xml -exec cp "{}" --target-directory=./test-results \;
      - store_artifacts:
          destination: << parameters.suiteName >>
          path: ./work/
      - store_test_results:
          path: ./test-results/

  run-hotbackup-tests:
    docker:
      - image: << pipeline.parameters.test-docker-image >>
    parameters:
      size:
        type: string
    resource_class: << parameters.size >>
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Enabled coredumps
          command: ulimit -c unlimited
      - run:
          name: Install dependencies
          command: |
            pip install -r scripts/toolbox/requirements.txt --break-system-packages
      - run:
          name: Run HotBackup tests
          command: |
            python3 scripts/toolbox/HotBackupConsistencyTest.py \
              --arangod $PWD/build/bin/arangod \
              --topdir $PWD \
              --workdir /tmp/test-workdir
      - run:
          name: Cleanup
          command: |
            rm -rf /tmp/test-workdir
      - store_artifacts:
          destination: hotbackup-test
          path: /tmp/test-workdir

  run-rta-tests:
    machine:
      image: ubuntu-2204:current
    resource_class: large
    parameters:
      suiteName:
        type: string
      enterprise:
        type: string
      deployment:
        type: string
      filterStatement:
        type: string
      browser:
        type: string
      # TODO add more parameters
    steps:
      - add_ssh_keys:
          fingerprints:
            - "f9:49:75:1a:ad:44:89:10:4b:3c:70:70:ba:d3:c3:ce"
      - attach_workspace:
          at: work/ArangoDB
      - run:
          name: Clone RTA
          command: |
            mkdir work/release-test-automation
            cd work/release-test-automation
            git clone git@github.com:arangodb/release-test-automation.git .
            #git checkout circleci
      - run:
          name: Run << parameters.suiteName >> tests
          no_output_timeout: 20m
          command: |
            pwd
            export SOURCE=nightlypublic
            export RTA_EDITION=<< parameters.enterprise >>
            mkdir -p  work/release-test-automation/allure-results work/release-test-automation/allure-config
            cd work/release-test-automation
            bash -x ./jenkins/circleci_tar.sh \
              --no-run-upgrade  \
              --selenium << parameters.browser >> \
              --starter-mode << parameters.deployment >> \
              << parameters.filterStatement >>
            exit_code=$?
            docker run \
             -v $(pwd)/allure-report:/allure-report \
             -v $(pwd)/allure-results:/allure-results \
             -v $(pwd)/allure-config:/allure-config \
             smartcosmos/allure-commandline generate /allure-results -o /allure-report --clean
             exit $(($exit_code + $(cat ./test_dir/status.json) ))
      - store_artifacts:
          destination: << parameters.suiteName >>
          path: ./work/release-test-automation/test_dir
      - store_artifacts:
          destination: << parameters.suiteName >>
          path: ./work/release-test-automation/allure-report
      - store_test_results:
          path: ./test-results/

  run-cppcheck:
    docker:
      - image: << pipeline.parameters.build-docker-image >>
    resource_class: medium+
    steps:
      - run:
          name: Prepare container
          command: |
            mkdir -p /root/workspace/ 
            mkdir -p /root/project/
      - attach_workspace:
          at: "/root/workspace/"
      - run:
          name: Print workspace size
          command: |
            du -sh /root/workspace/*
            echo ===================
            du -sh /root/workspace/build/*
            echo ===================
            du -sh /root/workspace/build/bin/*
      - checkout-arangodb:
          with-submodules: true
          destination: "/root/project"
      - checkout-enterprise:
          destination: "/root/project/enterprise"
      - run:
          name: Run cppcheck
          command: |
            ln -s /root/workspace/build/ /root/project/
            cd /root/project/ 
            utils/cppcheck-circleci.sh /root/workspace/build/compile_commands.json
      - run:
          name: Format result
          when: always
          command: |
            cd /root/project/ 
            sed -i 's/\/root\/project\/\/root\/project\///g' cppcheck.xml
            sed -i 's/\/root\/project\///g' cppcheck.xml
            cppcheck_junit cppcheck.xml cppcheck-junit.xml
      - store_artifacts:
          path: /root/project/cppcheck.xml
      - store_test_results:
          path: /root/project/cppcheck-junit.xml

workflows:
  lint:
    jobs:
      - minimal-checkout:
          name: minimal-checkout
      - check-log-ids:
          name: check-log-ids
          requires:
            - minimal-checkout
      - check-metrics-docs:
          name: check-metrics-docs
          requires:
            - minimal-checkout
      - clang-format:
          name: clang-format
          requires:
            - minimal-checkout
      - eslint:
          name: eslint
          context: [ circleci-token ]
          requires:
            - minimal-checkout
  # all other workflows are defined in generate_config.py
