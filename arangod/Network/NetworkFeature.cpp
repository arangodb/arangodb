////////////////////////////////////////////////////////////////////////////////
/// DISCLAIMER
///
/// Copyright 2014-2024 ArangoDB GmbH, Cologne, Germany
/// Copyright 2004-2014 triAGENS GmbH, Cologne, Germany
///
/// Licensed under the Business Source License 1.1 (the "License");
/// you may not use this file except in compliance with the License.
/// You may obtain a copy of the License at
///
///     https://github.com/arangodb/arangodb/blob/devel/LICENSE
///
/// Unless required by applicable law or agreed to in writing, software
/// distributed under the License is distributed on an "AS IS" BASIS,
/// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
/// See the License for the specific language governing permissions and
/// limitations under the License.
///
/// Copyright holder is ArangoDB GmbH, Cologne, Germany
///
/// @author Simon Gr√§tzer
////////////////////////////////////////////////////////////////////////////////

#include "NetworkFeature.h"

#include <fuerte/connection.h>

#include "ApplicationFeatures/ApplicationServer.h"
#include "Basics/EncodingUtils.h"
#include "Basics/FunctionUtils.h"
#include "Basics/NumberOfCores.h"
#include "Basics/ScopeGuard.h"
#include "Basics/application-exit.h"
#include "Basics/debugging.h"
#include "Cluster/ClusterFeature.h"
#include "Cluster/ClusterInfo.h"
#include "GeneralServer/GeneralServerFeature.h"
#include "Network/ConnectionPool.h"
#include "Network/Methods.h"
#include "ProgramOptions/ProgramOptions.h"
#include "ProgramOptions/Section.h"
#include "Metrics/CounterBuilder.h"
#include "Metrics/FixScale.h"
#include "Metrics/GaugeBuilder.h"
#include "Metrics/HistogramBuilder.h"
#include "Metrics/MetricsFeature.h"
#include "Scheduler/SchedulerFeature.h"

namespace {
void queueGarbageCollection(std::mutex& mutex,
                            arangodb::Scheduler::WorkHandle& workItem,
                            std::function<void(bool)>& gcfunc,
                            std::chrono::seconds offset) {
  std::lock_guard<std::mutex> guard(mutex);
  workItem = arangodb::SchedulerFeature::SCHEDULER->queueDelayed(
      "networkfeature-gc", arangodb::RequestLane::INTERNAL_LOW, offset, gcfunc);
}

constexpr double CongestionRatio = 0.5;
constexpr std::uint64_t MaxAllowedInFlight = 65536;
constexpr std::uint64_t MinAllowedInFlight = 64;
}  // namespace

using namespace arangodb::basics;
using namespace arangodb::options;

namespace arangodb {
struct NetworkFeatureScale {
  static metrics::FixScale<double> scale() {
    return {0.0, 100.0, {1.0, 5.0, 15.0, 50.0}};
  }
};

struct NetworkFeatureSendScaleSmall {
  static metrics::FixScale<double> scale() {
    return {0.0, 10.0, {0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0}};
  }
};

struct NetworkFeatureSendScaleLarge {
  static metrics::FixScale<double> scale() {
    return {0.0, 10000.0, {0.01, 0.1, 1.0, 10.0, 100.0, 1000.0}};
  }
};

DECLARE_COUNTER(arangodb_network_forwarded_requests_total,
                "Number of requests forwarded to another coordinator");
DECLARE_COUNTER(arangodb_network_request_timeouts_total,
                "Number of internal requests that have timed out");
DECLARE_HISTOGRAM(
    arangodb_network_request_duration_as_percentage_of_timeout,
    NetworkFeatureScale,
    "Internal request round-trip time as a percentage of timeout [%]");
DECLARE_COUNTER(arangodb_network_unfinished_sends_total,
                "Number of times the sending of a request remained unfinished");
DECLARE_HISTOGRAM(
    arangodb_network_dequeue_duration, NetworkFeatureSendScaleSmall,
    "Time to dequeue a queued network request in fuerte in seconds");
DECLARE_HISTOGRAM(arangodb_network_send_duration, NetworkFeatureSendScaleLarge,
                  "Time to send out internal requests in seconds");
DECLARE_HISTOGRAM(
    arangodb_network_response_duration, NetworkFeatureSendScaleLarge,
    "Time to wait for network response after it was sent out in seconds");
DECLARE_GAUGE(arangodb_network_requests_in_flight, uint64_t,
              "Number of outgoing internal requests in flight");

NetworkFeature::NetworkFeature(Server& server, metrics::MetricsFeature& metrics,
                               network::ConnectionPool::Config config)
    : ArangodFeature{server, *this},
      _protocol(),
      _maxOpenConnections(config.maxOpenConnections),
      _idleTtlMilli(config.idleConnectionMilli),
      _numIOThreads(defaultIOThreads()),
      _verifyHosts(config.verifyHosts),
      _prepared(false),
      _forwardedRequests(
          metrics.add(arangodb_network_forwarded_requests_total{})),
      _maxInFlight(::MaxAllowedInFlight),
      _requestsInFlight(metrics.add(arangodb_network_requests_in_flight{})),
      _requestTimeouts(metrics.add(arangodb_network_request_timeouts_total{})),
      _requestDurations(metrics.add(
          arangodb_network_request_duration_as_percentage_of_timeout{})),
      _unfinishedSends(metrics.add(arangodb_network_unfinished_sends_total{})),
      _dequeueDurations(metrics.add(arangodb_network_dequeue_duration{})),
      _sendDurations(metrics.add(arangodb_network_send_duration{})),
      _responseDurations(metrics.add(arangodb_network_response_duration{})),
      _compressRequestThreshold(200),
      // note: we cannot use any compression method by default here for the
      // 3.12 release because that could cause upgrades from 3.11 to 3.12
      // to break. for example, if we enable compression here and during the
      // upgrade the 3.12 servers could pick it up and send compressed
      // requests to 3.11 servers which cannot handle them.
      // we should set the compression type "auto" for future releases though
      // to save some traffic.
      _compressionType(CompressionType::kNone),
      _compressionTypeLabel("none"),
      _metrics(metrics) {
  setOptional(true);
  startsAfter<ClusterFeature>();
  startsAfter<SchedulerFeature>();
  startsAfter<ServerFeature>();
  startsAfter<EngineSelectorFeature>();
}

NetworkFeature::~NetworkFeature() {
  cancelRetryRequests();
  if (_pool) {
    _pool->stop();
  }
}

void NetworkFeature::collectOptions(
    std::shared_ptr<options::ProgramOptions> options) {
  options->addSection("network", "cluster-internal networking");

  options->addOption(
      "--network.io-threads",
      "The number of network I/O threads for cluster-internal "
      "communication.",
      new UInt32Parameter(&_numIOThreads, /*base*/ 1, /*minValue*/ 1));
  options->addOption(
      "--network.max-open-connections",
      "The maximum number of open TCP connections for "
      "cluster-internal communication per endpoint",
      new UInt64Parameter(&_maxOpenConnections, /*base*/ 1, /*minValue*/ 8));
  options->addOption("--network.idle-connection-ttl",
                     "The default time-to-live of idle connections for "
                     "cluster-internal communication (in milliseconds).",
                     new UInt64Parameter(&_idleTtlMilli));
  options->addOption(
      "--network.verify-hosts",
      "Verify peer certificates when using TLS in cluster-internal "
      "communication.",
      new BooleanParameter(&_verifyHosts));

  std::unordered_set<std::string> protos = {"", "http", "http2", "h2"};

  // starting with 3.9, we will hard-code the protocol for cluster-internal
  // communication
  options
      ->addOption(
          "--network.protocol",
          "The network protocol to use for cluster-internal communication.",
          new DiscreteValuesParameter<StringParameter>(&_protocol, protos),
          options::makeDefaultFlags(options::Flags::Uncommon))
      .setDeprecatedIn(30900);

  options
      ->addOption("--network.max-requests-in-flight",
                  "The number of internal requests that can be in "
                  "flight at a given point in time.",
                  new options::UInt64Parameter(&_maxInFlight),
                  options::makeDefaultFlags(options::Flags::Uncommon))
      .setIntroducedIn(30800);

  options
      ->addOption("--network.compress-request-threshold",
                  "The HTTP request body size from which on cluster-internal "
                  "requests are transparently compressed.",
                  new UInt64Parameter(&_compressRequestThreshold),
                  arangodb::options::makeFlags(
                      arangodb::options::Flags::DefaultNoComponents,
                      arangodb::options::Flags::OnDBServer,
                      arangodb::options::Flags::OnCoordinator))
      .setIntroducedIn(31200)
      .setLongDescription(
          R"(Automatically compress outgoing HTTP requests in cluster-internal
traffic with the deflate, gzip or lz4 compression format.
Compression will only happen if the size of the uncompressed request body exceeds 
the threshold value controlled by this startup option,
and if the request body size after compression is less than the original 
request body size.
Using the value 0 disables the automatic compression.")");

  std::unordered_set<std::string> types = {
      StaticStrings::EncodingGzip, StaticStrings::EncodingDeflate,
      StaticStrings::EncodingLz4, "auto", "none"};
  options
      ->addOption("--network.compression-method",
                  "The compression method used for cluster-internal requests.",
                  new DiscreteValuesParameter<StringParameter>(
                      &_compressionTypeLabel, types),
                  arangodb::options::makeFlags(
                      arangodb::options::Flags::DefaultNoComponents,
                      arangodb::options::Flags::OnDBServer,
                      arangodb::options::Flags::OnCoordinator))
      .setIntroducedIn(31200)
      .setLongDescription(
          R"(Setting this option to 'none' will disable compression for
cluster-internal requests.
To enable compression for cluster-internal requests, set this option to either
'deflate', 'gzip', 'lz4' or 'auto'.
The 'deflate' and 'gzip' compression methods are general purpose, 
but have significant CPU overhead for performing the compression work. 
The 'lz4' compression method compresses slightly worse, but has a lot lower 
CPU overhead for performing the compression.
The 'auto' compression method will use 'deflate' by default, and 'lz4' for
requests which have a size that is at least 3 times the configured threshold
size.
The compression method only matters if `--network.compress-request-threshold`
is set to value greater than zero. If the threshold is set to value of 0,
then no compression will be performed.)");
}

void NetworkFeature::validateOptions(
    std::shared_ptr<options::ProgramOptions> opts) {
  if (!opts->processingResult().touched("--network.idle-connection-ttl")) {
    auto& gs = server().getFeature<GeneralServerFeature>();
    _idleTtlMilli = uint64_t(gs.keepAliveTimeout() * 1000 / 2);
  }
  if (_idleTtlMilli < 10000) {
    _idleTtlMilli = 10000;
  }

  uint64_t clamped =
      std::clamp(_maxInFlight, ::MinAllowedInFlight, ::MaxAllowedInFlight);
  if (clamped != _maxInFlight) {
    LOG_TOPIC("38cd1", WARN, Logger::CONFIG)
        << "Must set --network.max-requests-in-flight between "
        << ::MinAllowedInFlight << " and " << ::MaxAllowedInFlight
        << ", clamping value";
    _maxInFlight = clamped;
  }

  if (_compressionTypeLabel == StaticStrings::EncodingGzip) {
    _compressionType = CompressionType::kGzip;
  } else if (_compressionTypeLabel == StaticStrings::EncodingDeflate) {
    _compressionType = CompressionType::kDeflate;
  } else if (_compressionTypeLabel == StaticStrings::EncodingLz4) {
    _compressionType = CompressionType::kLz4;
  } else if (_compressionTypeLabel == "auto") {
    _compressionType = CompressionType::kAuto;
  } else if (_compressionTypeLabel == "none") {
    _compressionType = CompressionType::kNone;
  } else {
    LOG_TOPIC("339d5", FATAL, Logger::CONFIG)
        << "invalid value for `--network.compression-method` ('"
        << _compressionTypeLabel << "')";
    FATAL_ERROR_EXIT();
  }
}

void NetworkFeature::prepare() {
  ClusterInfo* ci = nullptr;
  if (server().hasFeature<ClusterFeature>() &&
      server().isEnabled<ClusterFeature>()) {
    // in unit tests the ClusterInfo may not be enabled.
    ci = &server().getFeature<ClusterFeature>().clusterInfo();
  }

  network::ConnectionPool::Config config;
  config.numIOThreads = static_cast<unsigned>(_numIOThreads);
  config.maxOpenConnections = _maxOpenConnections;
  config.idleConnectionMilli = _idleTtlMilli;
  config.verifyHosts = _verifyHosts;
  config.clusterInfo = ci;
  config.name = "ClusterComm";
  config.metrics = network::ConnectionPool::Metrics::fromMetricsFeature(
      _metrics, config.name);

  // using an internal network protocol other than HTTP/1 is
  // not supported since 3.9. the protocol is always hard-coded
  // to HTTP/1 from now on.
  // note: we plan to upgrade the internal protocol to HTTP/2 at
  // some point in the future
  config.protocol = fuerte::ProtocolType::Http;
  if (_protocol == "http" || _protocol == "h1") {
    config.protocol = fuerte::ProtocolType::Http;
  } else if (_protocol == "http2" || _protocol == "h2") {
    config.protocol = fuerte::ProtocolType::Http2;
  }

  if (config.protocol != fuerte::ProtocolType::Http) {
    LOG_TOPIC("6d221", WARN, Logger::CONFIG)
        << "using `--network.protocol` is deprecated. "
        << "the network protocol for cluster-internal requests is hard-coded "
           "to HTTP/1 in this version";
    config.protocol = fuerte::ProtocolType::Http;
  }

  _pool = std::make_unique<network::ConnectionPool>(config);
  _poolPtr.store(_pool.get(), std::memory_order_relaxed);

  _gcfunc = [this, ci](bool canceled) {
    if (canceled) {
      return;
    }

    _pool->pruneConnections();

    if (ci != nullptr) {
      auto failed = ci->getFailedServers();
      for (ServerID const& srvId : failed) {
        std::string endpoint = ci->getServerEndpoint(srvId);
        size_t n = _pool->cancelConnections(endpoint);
        LOG_TOPIC_IF("15d94", INFO, Logger::COMMUNICATION, n > 0)
            << "canceling " << n << " connection(s) to failed server '" << srvId
            << "' on endpoint '" << endpoint << "'";
      }
    }

    if (!server().isStopping() && !canceled) {
      std::chrono::seconds off(12);
      ::queueGarbageCollection(_workItemMutex, _workItem, _gcfunc, off);
    }
  };

  _prepared = true;
}

void NetworkFeature::start() {
  Scheduler* scheduler = SchedulerFeature::SCHEDULER;
  if (scheduler != nullptr) {  // is nullptr in unit tests
    auto off = std::chrono::seconds(1);
    ::queueGarbageCollection(_workItemMutex, _workItem, _gcfunc, off);
  }
}

void NetworkFeature::beginShutdown() {
  cancelRetryRequests();
  _poolPtr.store(nullptr, std::memory_order_relaxed);
  if (_pool) {  // first cancel all connections
    _pool->shutdownConnections();
  }
}

void NetworkFeature::stop() {
  cancelRetryRequests();
  if (_pool) {
    _pool->shutdownConnections();
    _pool->drainConnections();
  }
}

void NetworkFeature::unprepare() {
  cancelRetryRequests();
  if (_pool) {
    _pool->stop();
  }
}

void NetworkFeature::cancelRetryRequests() noexcept try {
  std::lock_guard<std::mutex> guard(_workItemMutex);
  _workItem.reset();
  for (auto const& [req, item] : _retryRequests) {
    TRI_ASSERT(item != nullptr);
    item->cancel();
  }
  _retryRequests.clear();
} catch (std::exception const& ex) {
  LOG_TOPIC("2b843", WARN, Logger::COMMUNICATION)
      << "caught exception while canceling retry requests: " << ex.what();
}

network::ConnectionPool* NetworkFeature::pool() const noexcept {
  return _poolPtr.load(std::memory_order_relaxed);
}

#ifdef ARANGODB_USE_GOOGLE_TESTS
void NetworkFeature::setPoolTesting(network::ConnectionPool* pool) {
  _poolPtr.store(pool, std::memory_order_release);
}
#endif

bool NetworkFeature::prepared() const noexcept { return _prepared; }

void NetworkFeature::trackForwardedRequest() noexcept { ++_forwardedRequests; }

std::size_t NetworkFeature::requestsInFlight() const noexcept {
  return _requestsInFlight.load();
}

bool NetworkFeature::isCongested() const noexcept {
  return _requestsInFlight.load() >= (_maxInFlight * ::CongestionRatio);
}

bool NetworkFeature::isSaturated() const noexcept {
  return _requestsInFlight.load() >= _maxInFlight;
}

uint64_t NetworkFeature::defaultIOThreads() {
  return std::max(uint64_t(1), uint64_t(NumberOfCores::getValue() / 4));
}

void NetworkFeature::sendRequest(network::ConnectionPool& pool,
                                 network::RequestOptions const& options,
                                 std::string const& endpoint,
                                 std::unique_ptr<fuerte::Request>&& req,
                                 RequestCallback&& cb) {
  TRI_ASSERT(req != nullptr);

  injectAcceptEncodingHeader(*req);

  bool didCompress = compressRequestBody(options, *req);

  prepareRequest(pool, req);

  bool isFromPool = false;
  auto now = std::chrono::steady_clock::now();
  auto conn = pool.leaseConnection(endpoint, isFromPool);
  auto dur = std::chrono::steady_clock::now() - now;
  if (dur > std::chrono::seconds(1)) {
    LOG_TOPIC("52418", WARN, Logger::COMMUNICATION)
        << "have leased connection to '" << endpoint
        << "' came from pool: " << isFromPool << " leasing took "
        << std::chrono::duration_cast<std::chrono::duration<double>>(dur)
               .count()
        << " seconds, url: " << to_string(req->header.restVerb) << " "
        << req->header.path << ", request ptr: " << (void*)req.get();
  } else {
    LOG_TOPIC("52417", TRACE, Logger::COMMUNICATION)
        << "have leased connection to '" << endpoint
        << "' came from pool: " << isFromPool
        << ", url: " << to_string(req->header.restVerb) << " "
        << req->header.path << ", request ptr: " << (void*)req.get();
  }
  conn->sendRequest(
      std::move(req),
      [this, &pool, isFromPool,
       handleContentEncoding = options.handleContentEncoding || didCompress,
       cb = std::move(cb), endpoint = std::move(endpoint)](
          fuerte::Error err, std::unique_ptr<fuerte::Request> req,
          std::unique_ptr<fuerte::Response> res) {
        TRI_ASSERT(req != nullptr);
        if (req->timeQueued().time_since_epoch().count() != 0 &&
            req->timeAsyncWrite().time_since_epoch().count() != 0) {
          // In the 0 cases fuerte did not even accept or start to send
          // the request, so there is nothing to report.
          auto dur = std::chrono::duration_cast<std::chrono::duration<double>>(
              req->timeAsyncWrite() - req->timeQueued());
          _dequeueDurations.count(dur.count());
          if (req->timeSent().time_since_epoch().count() == 0) {
            // The request sending was never finished. This could be a timeout
            // during the sending phase.
            LOG_TOPIC("effc3", DEBUG, Logger::COMMUNICATION)
                << "Time to dequeue request to " << endpoint << ": "
                << dur.count()
                << " seconds, however, the sending has not yet finished so far"
                << ", endpoint: " << endpoint
                << ", request ptr: " << (void*)req.get()
                << ", response ptr: " << (void*)res.get()
                << ", error: " << uint16_t(err);
            _unfinishedSends.count();
          } else {
            // The request was fully sent off, we have received the callback
            // from asio.
            dur = std::chrono::duration_cast<std::chrono::duration<double>>(
                req->timeSent() - req->timeAsyncWrite());
            _sendDurations.count(dur.count());
            // If you suspect network delays in your infrastructure, you
            // can use the following log message to track them down and
            // to associate them with particular requests:
            LOG_TOPIC_IF("effc4", DEBUG, Logger::COMMUNICATION,
                         dur > std::chrono::seconds(3))
                << "Time to send request to " << endpoint << ": " << dur.count()
                << " seconds, endpoint: " << endpoint
                << ", request ptr: " << (void*)req.get()
                << ", response ptr: " << (void*)res.get()
                << ", error: " << uint16_t(err);

            dur = std::chrono::duration_cast<std::chrono::duration<double>>(
                std::chrono::steady_clock::now() - req->timeSent());
            // If you suspect network delays in your infrastructure, you
            // can use the following log message to track them down and
            // to associate them with particular requests:
            LOG_TOPIC_IF("effc5", DEBUG, Logger::COMMUNICATION,
                         dur > std::chrono::seconds(61))
                << "Time since request was sent out to " << endpoint
                << " until now was " << dur.count()
                << " seconds, endpoint: " << endpoint
                << ", request ptr: " << (void*)req.get()
                << ", response ptr: " << (void*)res.get()
                << ", error: " << uint16_t(err);
            _responseDurations.count(dur.count());
          }
        }
        finishRequest(pool, err, req, res);
        if (res != nullptr && handleContentEncoding) {
          // transparently handle decompression
          auto const& encoding =
              res->header.metaByKey(StaticStrings::ContentEncoding);
          if (encoding == StaticStrings::EncodingGzip) {
            velocypack::Buffer<uint8_t> uncompressed;
            auto r = encoding::gzipUncompress(
                reinterpret_cast<uint8_t const*>(res->payload().data()),
                res->payload().size(), uncompressed);
            if (r != TRI_ERROR_NO_ERROR) {
              THROW_ARANGO_EXCEPTION(r);
            }
            // replace response body and remove "content-encoding"
            // handler to prevent duplicate uncompression
            res->setPayload(std::move(uncompressed), 0);
            res->header.contentEncoding(fuerte::ContentEncoding::Identity);
            res->header.removeMeta(StaticStrings::ContentEncoding);
          } else if (encoding == StaticStrings::EncodingDeflate) {
            velocypack::Buffer<uint8_t> uncompressed;
            auto r = encoding::zlibInflate(
                reinterpret_cast<uint8_t const*>(res->payload().data()),
                res->payload().size(), uncompressed);
            if (r != TRI_ERROR_NO_ERROR) {
              THROW_ARANGO_EXCEPTION(r);
            }
            // replace response body and remove "content-encoding"
            // handler to prevent duplicate uncompression
            res->setPayload(std::move(uncompressed), 0);
            res->header.contentEncoding(fuerte::ContentEncoding::Identity);
            res->header.removeMeta(StaticStrings::ContentEncoding);
          } else if (encoding == StaticStrings::EncodingArangoLz4) {
            velocypack::Buffer<uint8_t> uncompressed;
            auto r = encoding::lz4Uncompress(
                reinterpret_cast<uint8_t const*>(res->payload().data()),
                res->payload().size(), uncompressed);
            if (r != TRI_ERROR_NO_ERROR) {
              THROW_ARANGO_EXCEPTION(r);
            }
            // replace response body and remove "content-encoding"
            // handler to prevent duplicate uncompression
            res->setPayload(std::move(uncompressed), 0);
            res->header.contentEncoding(fuerte::ContentEncoding::Identity);
            res->header.removeMeta(StaticStrings::ContentEncoding);
          }
        }
        cb(err, std::move(req), std::move(res), isFromPool);
      });
}

void NetworkFeature::prepareRequest(network::ConnectionPool const& pool,
                                    std::unique_ptr<fuerte::Request>& req) {
  _requestsInFlight += 1;
  if (req) {
    req->timestamp(std::chrono::steady_clock::now());
  }
}

void NetworkFeature::finishRequest(network::ConnectionPool const& pool,
                                   fuerte::Error err,
                                   std::unique_ptr<fuerte::Request> const& req,
                                   std::unique_ptr<fuerte::Response>& res) {
  _requestsInFlight -= 1;
  if (err == fuerte::Error::RequestTimeout) {
    _requestTimeouts.count();
  } else if (req && res) {
    res->timestamp(std::chrono::steady_clock::now());
    std::chrono::milliseconds duration =
        std::chrono::duration_cast<std::chrono::milliseconds>(res->timestamp() -
                                                              req->timestamp());
    std::chrono::milliseconds timeout = req->timeout();
    TRI_ASSERT(timeout.count() > 0);
    if (timeout.count() > 0) {
      // only go in here if we are sure to not divide by zero
      double percentage =
          std::clamp(100.0 * static_cast<double>(duration.count()) /
                         static_cast<double>(timeout.count()),
                     0.0, 100.0);
      _requestDurations.count(percentage);
    } else {
      // the timeout value was 0, for whatever reason. this is unexpected,
      // but we must not make the program crash here.
      // so instead log a warning and interpret this as a request that took
      // 100% of the timeout duration.
      _requestDurations.count(100.0);
      LOG_TOPIC("1688c", WARN, Logger::FIXME)
          << "encountered invalid 0s timeout for internal request to path "
          << req->header.path;
    }
  }
}

void NetworkFeature::retryRequest(
    std::shared_ptr<network::RetryableRequest> req, RequestLane lane,
    std::chrono::steady_clock::duration duration) {
  auto cb = [this, weak = std::weak_ptr(req)](bool cancelled) {
    std::unique_lock guard(_workItemMutex);
    if (auto self = weak.lock(); self) {
      _retryRequests.erase(self);
      guard.unlock();  // resuming the request does not access _retryRequests
      if (cancelled) {
        self->cancel();
      } else {
        self->retry();
      }
    }
  };

  // we need the mutex during `queueDelayed` because the lambda might be
  // executed faster than we can add the work item to the _retryRequests map.
  std::unique_lock guard(_workItemMutex);

  // this will automatically cancel the request when we leave this
  // method, unless we are canceling this scopeGuard explicitly.
  auto cancelGuard = scopeGuard([req]() noexcept {
    if (req) {
      req->cancel();
    }
  });

  if (server().isStopping()) {
    // with trigger cancelGuard - cancels request
    return;
  }

  auto item = SchedulerFeature::SCHEDULER->queueDelayed(
      "retry-requests", lane, duration, std::move(cb));

  if (item != nullptr) {
    try {
      TRI_IF_FAILURE("NetworkFeature::retryRequestFail") {
        THROW_ARANGO_EXCEPTION(TRI_ERROR_DEBUG);
      }

      _retryRequests.emplace(std::move(req), std::move(item));
      // the request successfully made it into _retryRequests.
      // now abandon the automatic cancelation.
      cancelGuard.cancel();
    } catch (...) {
    }
  }
  // if we get here and haven't canceled cancelGuard,
  // the request will be automatically canceled
}

void NetworkFeature::injectAcceptEncodingHeader(fuerte::Request& req) const {
  // inject "Accept-Encoding" header into the request if it was not
  // already set.
  if (req.header.meta().contains(StaticStrings::AcceptEncoding)) {
    // header already set in original request
    return;
  }

  if (_compressionType == CompressionType::kNone) {
    return;
  }

  if (_compressionType == CompressionType::kDeflate) {
    // if cluster-internal compression type is set to "deflate", add
    // "accept-encoding: deflate" header
    req.header.addMeta(StaticStrings::AcceptEncoding,
                       StaticStrings::EncodingDeflate);
  } else if (_compressionType == CompressionType::kGzip) {
    // if cluster-internal compression type is set to "gzip", add
    // "accept-encoding: gzip, deflate" header. we leave "deflate" in
    // as a general fallback
    req.header.addMeta(StaticStrings::AcceptEncoding,
                       absl::StrCat(StaticStrings::EncodingGzip, ",",
                                    StaticStrings::EncodingDeflate));
  } else if (_compressionType == CompressionType::kLz4 ||
             _compressionType == CompressionType::kAuto) {
    // if cluster-internal compression type is set to "lz4", add
    // "accept-encoding: lz4, deflate" header. we leave "deflate" in
    // as a general fallback
    req.header.addMeta(StaticStrings::AcceptEncoding,
                       absl::StrCat(StaticStrings::EncodingArangoLz4, ",",
                                    StaticStrings::EncodingDeflate));
  } else {
    TRI_ASSERT(false);
  }
}

bool NetworkFeature::compressRequestBody(network::RequestOptions const& opts,
                                         fuerte::Request& req) const {
  if (!opts.allowCompression) {
    // compression explicitly disallowed
    return false;
  }

  uint64_t threshold = _compressRequestThreshold;
  if (threshold == 0) {
    // opted out of compression by configuration
    return false;
  }

  if (_compressionType == CompressionType::kNone) {
    return false;
  }

  if (req.header.meta().contains(StaticStrings::ContentEncoding)) {
    // Content-Encoding already set. better not overwrite it
    return false;
  }

  auto& pfm = req.payloadForModification();
  size_t bodySize = pfm.size();
  if (bodySize < threshold) {
    // request body size too small for compression
    return false;
  }

  auto compressionType = _compressionType;

  if (compressionType == CompressionType::kAuto) {
    // "auto" compression means that we will pick deflate for all
    // requests that exceed the threshold size, and lz4 for all
    // requests with substantially larger ones
    compressionType = CompressionType::kDeflate;
    if (bodySize >= threshold * 3) {
      compressionType = CompressionType::kLz4;
    }
  }

  TRI_ASSERT(compressionType != CompressionType::kNone);
  TRI_ASSERT(compressionType != CompressionType::kAuto);

  velocypack::Buffer<uint8_t> compressed;
  if (compressionType == CompressionType::kDeflate) {
    if (encoding::zlibDeflate(pfm.data(), pfm.size(), compressed) !=
        TRI_ERROR_NO_ERROR) {
      return false;
    }

    if (compressed.size() >= bodySize) {
      // compression did not provide any benefit. better leave it
      return false;
    }

    pfm = std::move(compressed);
    req.header.addMeta(StaticStrings::ContentEncoding,
                       StaticStrings::EncodingDeflate);
  } else if (compressionType == CompressionType::kGzip) {
    if (encoding::gzipCompress(pfm.data(), pfm.size(), compressed) !=
        TRI_ERROR_NO_ERROR) {
      return false;
    }

    if (compressed.size() >= bodySize) {
      // compression did not provide any benefit. better leave it
      return false;
    }

    pfm = std::move(compressed);
    req.header.addMeta(StaticStrings::ContentEncoding,
                       StaticStrings::EncodingGzip);
  } else if (compressionType == CompressionType::kLz4) {
    if (encoding::lz4Compress(pfm.data(), pfm.size(), compressed) !=
        TRI_ERROR_NO_ERROR) {
      return false;
    }

    if (compressed.size() >= bodySize) {
      // compression did not provide any benefit. better leave it
      return false;
    }

    pfm = std::move(compressed);
    req.header.addMeta(StaticStrings::ContentEncoding,
                       StaticStrings::EncodingArangoLz4);
  } else {
    // unknown compression type
    return false;
  }

  return true;
}

}  // namespace arangodb
